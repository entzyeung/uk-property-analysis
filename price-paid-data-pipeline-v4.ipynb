{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b9446d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T08:29:57.876963Z",
     "iopub.status.busy": "2025-02-22T08:29:57.876496Z",
     "iopub.status.idle": "2025-02-22T08:34:37.550878Z",
     "shell.execute_reply": "2025-02-22T08:34:37.549115Z"
    },
    "papermill": {
     "duration": 279.681649,
     "end_time": "2025-02-22T08:34:37.553723",
     "exception": false,
     "start_time": "2025-02-22T08:29:57.872074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the latest version of Kaggle dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/lorentzyeung/price-paid-data-202304\r\n",
      "License(s): other\r\n",
      "Downloading price-paid-data-202304.zip to ./temp_kaggle_data\r\n",
      " 99%|██████████████████████████████████████▋| 1.40G/1.41G [00:07<00:00, 175MB/s]\r\n",
      "100%|███████████████████████████████████████| 1.41G/1.41G [00:07<00:00, 190MB/s]\r\n",
      "Download complete. Using data from: ./temp_kaggle_data/\n",
      "Kaggle input directory set to: ./temp_kaggle_data/\n",
      "Files in Kaggle input directory: ['December 2024 data.csv', 'pp-complete.csv', 'last_update.txt', 'March 2024 data.csv']\n",
      "Checking file: December 2024 data.csv\n",
      "  Source: ./temp_kaggle_data/December 2024 data.csv\n",
      "  Destination: ./data/December 2024 data.csv\n",
      "Copying existing monthly file: December 2024 data.csv\n",
      "Checking file: March 2024 data.csv\n",
      "  Source: ./temp_kaggle_data/March 2024 data.csv\n",
      "  Destination: ./data/March 2024 data.csv\n",
      "Copying existing monthly file: March 2024 data.csv\n",
      "Contents of DATA_DIR before update: ['December 2024 data.csv', 'March 2024 data.csv']\n",
      "Found last_update.txt in dataset. Loading...\n",
      "\n",
      "\n",
      "The record on last_update.txt is: December 2023 data\n",
      "\n",
      "\n",
      "stored_month = December 2023 data\n",
      "current_month = December 2024 data\n",
      "Set global NEED_TO_UPDATE = True...\n",
      "New update detected: December 2024 data (Previous: December 2023 data)\n",
      "Monthly file December 2024 data.csv already exists. Skipping download for monthly file.\n",
      "Complete file link found: http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv\n",
      "Downloading complete file as: pp-complete.csv\n",
      "Downloading to ./data/pp-complete.csv...\n",
      "Downloaded 5219.07 MB\n",
      "Download complete!\n",
      "Updated last_update.txt with new value.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Step 1. Force-refresh the Kaggle dataset by downloading its latest version\n",
    "# Define the full dataset slug\n",
    "DATASET_SLUG = \"lorentzyeung/price-paid-data-202304\"\n",
    "\n",
    "# Temporary directory to hold the refreshed dataset files\n",
    "REFRESHED_DATASET_DIR = \"./temp_kaggle_data/\"\n",
    "if os.path.exists(REFRESHED_DATASET_DIR):\n",
    "    shutil.rmtree(REFRESHED_DATASET_DIR)\n",
    "os.makedirs(REFRESHED_DATASET_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Downloading the latest version of Kaggle dataset...\")\n",
    "!kaggle datasets download -d {DATASET_SLUG} -p {REFRESHED_DATASET_DIR} --unzip\n",
    "print(\"Download complete. Using data from:\", REFRESHED_DATASET_DIR)\n",
    "\n",
    "# Use the refreshed folder as our input directory\n",
    "KAGGLE_INPUT_DIR = REFRESHED_DATASET_DIR\n",
    "print(\"Kaggle input directory set to:\", KAGGLE_INPUT_DIR)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Step 2. Set up local working directories\n",
    "DATA_DIR = \"./data/\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "LAST_UPDATE_FILE = os.path.join(DATA_DIR, \"last_update.txt\")\n",
    "\n",
    "# Official Gov.uk Price Paid Data page\n",
    "URL = \"https://www.gov.uk/government/statistical-data-sets/price-paid-data-downloads\"\n",
    "\n",
    "NEED_TO_UPDATE = False\n",
    "\n",
    "def get_current_month():\n",
    "    \"\"\"\n",
    "    Fetch the webpage and extract the current month information from the h2 tag.\n",
    "    Expected h2 tag format:\n",
    "    <h2 id=\"december-2024-data-current-month\">December 2024 data (current month)</h2>\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(URL)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        h2_tag = soup.find(\"h2\", id=lambda x: x and \"data-current-month\" in x)\n",
    "        if h2_tag:\n",
    "            text = h2_tag.get_text(strip=True)\n",
    "            # Remove the \" (current month)\" part\n",
    "            current_month = text.split(\" (\")[0].strip()  # e.g. \"December 2024 data\"\n",
    "            return current_month, soup\n",
    "        else:\n",
    "            print(\"Could not find the current month information on the page.\")\n",
    "            return None, soup\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching the page: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def get_stored_update():\n",
    "    \"\"\"\n",
    "    Retrieve last_update.txt from the refreshed Kaggle dataset.\n",
    "    If it does not exist, create an empty one.\n",
    "    \"\"\"\n",
    "    kaggle_last_update_path = os.path.join(KAGGLE_INPUT_DIR, \"last_update.txt\")\n",
    "    if os.path.exists(kaggle_last_update_path):\n",
    "        print(\"Found last_update.txt in dataset. Loading...\")\n",
    "        shutil.copy(kaggle_last_update_path, LAST_UPDATE_FILE)\n",
    "    else:\n",
    "        print(\"last_update.txt not found in dataset. Creating a new one.\")\n",
    "        with open(LAST_UPDATE_FILE, \"w\") as file:\n",
    "            file.write(\"\")  # Create an empty file\n",
    "\n",
    "    # Read and return the stored value\n",
    "    with open(LAST_UPDATE_FILE, \"r\") as file:\n",
    "        content = file.read().strip()\n",
    "        print(f\"\\n\\nThe record on last_update.txt is: {content}\\n\\n\")\n",
    "        return content\n",
    "\n",
    "def store_update(new_value):\n",
    "    \"\"\"Store the new update value in last_update.txt\"\"\"\n",
    "    with open(LAST_UPDATE_FILE, \"w\") as file:\n",
    "        file.write(new_value)\n",
    "    print(\"Updated last_update.txt with new value.\")\n",
    "\n",
    "def load_existing_monthly_files():\n",
    "    \"\"\"\n",
    "    Copy all CSV files from the refreshed Kaggle dataset folder (KAGGLE_INPUT_DIR) into the local DATA_DIR.\n",
    "    This preserves previously accumulated monthly files.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(KAGGLE_INPUT_DIR):\n",
    "        print(f\"Kaggle input directory {KAGGLE_INPUT_DIR} not found!\")\n",
    "        return\n",
    "    print(\"Files in Kaggle input directory:\", os.listdir(KAGGLE_INPUT_DIR))\n",
    "    \n",
    "    for filename in os.listdir(KAGGLE_INPUT_DIR):\n",
    "        if filename.endswith('.csv') and filename not in [\"pp-complete.csv\", \"last_update.txt\", \"dataset-metadata.json\"]:\n",
    "            src = os.path.join(KAGGLE_INPUT_DIR, filename)\n",
    "            dest = os.path.join(DATA_DIR, filename)\n",
    "            print(f\"Checking file: {filename}\")\n",
    "            print(f\"  Source: {src}\")\n",
    "            print(f\"  Destination: {dest}\")\n",
    "            if not os.path.exists(dest):\n",
    "                print(f\"Copying existing monthly file: {filename}\")\n",
    "                shutil.copy(src, dest)\n",
    "            else:\n",
    "                print(f\"Monthly file {filename} already exists locally; skipping copy.\")\n",
    "\n",
    "def find_monthly_csv_download_link(soup):\n",
    "    \"\"\"\n",
    "    Find the CSV download link for the monthly file by searching for \n",
    "    'pp-monthly-update-new-version.csv' in the href.\n",
    "    \"\"\"\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        if \"pp-monthly-update-new-version.csv\" in a[\"href\"]:\n",
    "            return a[\"href\"]\n",
    "    return None\n",
    "\n",
    "def find_csv_download_link(soup):\n",
    "    \"\"\"\n",
    "    Find the CSV download link for the complete dataset by searching for \n",
    "    'pp-complete.csv' in the href.\n",
    "    \"\"\"\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        if \"pp-complete.csv\" in a[\"href\"]:\n",
    "            return a[\"href\"]\n",
    "    return None\n",
    "\n",
    "def get_monthly_file_name(soup):\n",
    "    \"\"\"\n",
    "    Extract the monthly file name from the h2 tag.\n",
    "    For example, if the h2 text is 'December 2024 data (current month)',\n",
    "    return 'December 2024 data.csv'.\n",
    "    \"\"\"\n",
    "    h2_tag = soup.find(\"h2\", id=lambda x: x and \"data-current-month\" in x)\n",
    "    if h2_tag:\n",
    "        text = h2_tag.get_text(strip=True)\n",
    "        name = text.split(\" (\")[0]  # e.g. \"December 2024 data\"\n",
    "        return f\"{name}.csv\"\n",
    "    return None\n",
    "\n",
    "def download_file(url, output_filename):\n",
    "    \"\"\"\n",
    "    Download the file from the given URL to DATA_DIR using the specified output filename.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(DATA_DIR, output_filename)\n",
    "    print(f\"Downloading to {file_path}...\")\n",
    "    try:\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            total_size = int(r.headers.get('content-length', 0))\n",
    "            downloaded = 0\n",
    "            chunk_size = 8192  # 8KB chunks\n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        downloaded += len(chunk)\n",
    "                        print(f\"\\rDownloaded {downloaded / 1e6:.2f} MB\", end='')\n",
    "        print(\"\\nDownload complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to check for an update based on the current month.\n",
    "    If the current month (extracted from the h2 tag) has changed since the last run,\n",
    "    download the monthly file (if not already downloaded) first, then the complete file.\n",
    "    \"\"\"\n",
    "    global NEED_TO_UPDATE\n",
    "    \n",
    "    load_existing_monthly_files()\n",
    "    print(\"Contents of DATA_DIR before update:\", os.listdir(DATA_DIR))\n",
    "    \n",
    "    current_month, soup = get_current_month() # webpage month\n",
    "\n",
    "    \n",
    "    if not current_month:\n",
    "        print(\"No current month information found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    stored_month = get_stored_update()\n",
    "\n",
    "    # if current_month != stored_month:\n",
    "    #    NEED_TO_UPDATE = True\n",
    "        \n",
    "    print(f\"stored_month = {stored_month}\")\n",
    "    print(f\"current_month = {current_month}\")  \n",
    "\n",
    "    if stored_month == current_month:\n",
    "        print(\"No update detected for the current month. Skipping download.\")\n",
    "    else:\n",
    "        # -------------------------------------------\n",
    "        # update the universal var NEED_TO_UPDATE\n",
    "        NEED_TO_UPDATE = True\n",
    "        print(f\"Set global NEED_TO_UPDATE = True...\")\n",
    "        # -------------------------------------------\n",
    "        \n",
    "        print(f\"New update detected: {current_month} (Previous: {stored_month})\")\n",
    "        # --- Download the monthly file if not already present ---\n",
    "        monthly_link = find_monthly_csv_download_link(soup)\n",
    "        monthly_filename = get_monthly_file_name(soup)\n",
    "        if monthly_link and monthly_filename:\n",
    "            monthly_file_path = os.path.join(DATA_DIR, monthly_filename)\n",
    "            if os.path.exists(monthly_file_path):\n",
    "                print(f\"Monthly file {monthly_filename} already exists. Skipping download for monthly file.\")\n",
    "            else:\n",
    "                if monthly_link.startswith(\"/\"):\n",
    "                    monthly_link = \"https://www.gov.uk\" + monthly_link\n",
    "                print(f\"Monthly file link found: {monthly_link}\")\n",
    "                print(f\"Downloading monthly file as: {monthly_filename}\")\n",
    "                download_file(monthly_link, monthly_filename)\n",
    "        else:\n",
    "            print(\"Could not find the monthly file download link or file name.\")\n",
    "        \n",
    "        # --- Download the complete (huge) file (always replace) ---\n",
    "        complete_link = find_csv_download_link(soup)\n",
    "        if complete_link:\n",
    "            if complete_link.startswith(\"/\"):\n",
    "                complete_link = \"https://www.gov.uk\" + complete_link\n",
    "            complete_filename = \"pp-complete.csv\"\n",
    "            print(f\"Complete file link found: {complete_link}\")\n",
    "            print(f\"Downloading complete file as: {complete_filename}\")\n",
    "            download_file(complete_link, complete_filename)\n",
    "        else:\n",
    "            print(\"Could not find the complete file download link.\")\n",
    "        \n",
    "        # Update the stored update key with the current month\n",
    "        store_update(current_month)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f07bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T08:34:39.220767Z",
     "iopub.status.busy": "2025-02-22T08:34:39.219678Z",
     "iopub.status.idle": "2025-02-22T08:39:45.604869Z",
     "shell.execute_reply": "2025-02-22T08:39:45.603104Z"
    },
    "papermill": {
     "duration": 307.183207,
     "end_time": "2025-02-22T08:39:45.608489",
     "exception": false,
     "start_time": "2025-02-22T08:34:38.425282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "csv_file_path = os.path.join(DATA_DIR, \"pp-complete.csv\")\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Remove the first column - \n",
    "df = df.iloc[:, 1:]\n",
    "\n",
    "# Save the DataFrame back to the same CSV file (overwriting it)\n",
    "df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d17e834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T08:39:47.178811Z",
     "iopub.status.busy": "2025-02-22T08:39:47.178330Z",
     "iopub.status.idle": "2025-02-22T08:40:38.013788Z",
     "shell.execute_reply": "2025-02-22T08:40:38.012342Z"
    },
    "papermill": {
     "duration": 51.620923,
     "end_time": "2025-02-22T08:40:38.016035",
     "exception": false,
     "start_time": "2025-02-22T08:39:46.395112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset-metadata.json created at ./data/dataset-metadata.json\n",
      "Files found in ./data/. Proceeding with dataset update...\n",
      "Starting upload for file December 2024 data.csv\r\n",
      "100%|██████████████████████████████████████| 13.0M/13.0M [00:00<00:00, 17.8MB/s]\r\n",
      "Upload successful: December 2024 data.csv (13MB)\r\n",
      "Starting upload for file pp-complete.csv\r\n",
      "100%|██████████████████████████████████████| 2.89G/2.89G [00:45<00:00, 68.6MB/s]\r\n",
      "Upload successful: pp-complete.csv (3GB)\r\n",
      "Starting upload for file last_update.txt\r\n",
      "100%|█████████████████████████████████████████| 18.0/18.0 [00:00<00:00, 28.2B/s]\r\n",
      "Upload successful: last_update.txt (18B)\r\n",
      "Starting upload for file March 2024 data.csv\r\n",
      "100%|██████████████████████████████████████| 16.1M/16.1M [00:00<00:00, 19.2MB/s]\r\n",
      "Upload successful: March 2024 data.csv (16MB)\r\n",
      "Dataset version is being created. Please check progress at https://www.kaggle.com/lorentzyeung/price-paid-data-202304\r\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# Step 3. Update the Kaggle dataset with the new files\n",
    "if NEED_TO_UPDATE == True:\n",
    "    user_secrets = UserSecretsClient()\n",
    "    kaggle_api_key = user_secrets.get_secret(\"kaggle-api\")\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = \"lorentzyeung\"\n",
    "    os.environ[\"KAGGLE_KEY\"] = kaggle_api_key\n",
    "    \n",
    "    # Define metadata for the dataset update\n",
    "    metadata = {\n",
    "        \"title\": \"UK Property Price official data (Monthly Update)\",\n",
    "        \"id\": \"lorentzyeung/price-paid-data-202304\",\n",
    "        \"licenses\": [{\"name\": \"CC0-1.0\"}]\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(DATA_DIR, \"dataset-metadata.json\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(f\"dataset-metadata.json created at {metadata_path}\")\n",
    "    \n",
    "    # If there are files in DATA_DIR, create a new dataset version\n",
    "    if len(os.listdir(DATA_DIR)) > 0:\n",
    "        print(\"Files found in ./data/. Proceeding with dataset update...\")\n",
    "        !kaggle datasets version -p ./data -m \"Automatic update: last_update.txt retrieved and updated, new monthly file added, pp-complete.csv replaced\" --dir-mode=tar\n",
    "    else:\n",
    "        print(\"No files in ./data/. Skipping dataset update.\")\n",
    "else:\n",
    "    print(\"No update detected, skipping the push... Let's call it a day!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21577025",
   "metadata": {
    "papermill": {
     "duration": 0.911279,
     "end_time": "2025-02-22T08:40:39.668243",
     "exception": false,
     "start_time": "2025-02-22T08:40:38.756964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3754341,
     "sourceId": 10818136,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 649.147397,
   "end_time": "2025-02-22T08:40:44.164073",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-22T08:29:55.016676",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
