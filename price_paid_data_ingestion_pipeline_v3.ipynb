{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976280bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T20:33:43.231869Z",
     "iopub.status.busy": "2025-02-18T20:33:43.231441Z",
     "iopub.status.idle": "2025-02-18T20:37:43.744206Z",
     "shell.execute_reply": "2025-02-18T20:37:43.742047Z"
    },
    "papermill": {
     "duration": 240.51955,
     "end_time": "2025-02-18T20:37:43.746632",
     "exception": false,
     "start_time": "2025-02-18T20:33:43.227082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/price-paid-data-202304/\n",
      "Copying existing monthly file: December 2024 data.csv\n",
      "Copying existing monthly file: December 2023 data.csv\n",
      "Found last_update.txt in dataset. Loading...\n",
      "New update detected: December 2024 data (Previous: October 2024 data\n",
      "November 2024 data)\n",
      "Monthly file link found: http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-monthly-update-new-version.csv\n",
      "Downloading monthly file as: December 2024 data.csv\n",
      "Downloading to ./data/December 2024 data.csv...\n",
      "Downloaded 13.59 MB\n",
      "Download complete!\n",
      "Complete file link found: http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv\n",
      "Downloading complete file as: pp-complete.csv\n",
      "Downloading to ./data/pp-complete.csv...\n",
      "Downloaded 5219.07 MB\n",
      "Download complete!\n",
      "Updated last_update.txt with new value.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from bs4 import BeautifulSoup  # Fix missing import\n",
    "\n",
    "\n",
    "# My Kaggle dataset\n",
    "KAGGLE_DATASET = \"price-paid-data-202304\"\n",
    "\n",
    "# Kaggle input directory where dataset files are stored\n",
    "KAGGLE_INPUT_DIR = f\"/kaggle/input/{KAGGLE_DATASET}/\"\n",
    "# /kaggle/input/price-paid-data-202304\n",
    "print(KAGGLE_INPUT_DIR)\n",
    "\n",
    "# Work directory inside the notebook\n",
    "DATA_DIR = \"./data/\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# File path for last_update.txt inside the notebook\n",
    "LAST_UPDATE_FILE = os.path.join(DATA_DIR, \"last_update.txt\")\n",
    "\n",
    "\n",
    "# Official Statistical data set Price Paid Data\n",
    "URL = \"https://www.gov.uk/government/statistical-data-sets/price-paid-data-downloads\"\n",
    "\n",
    "def get_current_month():\n",
    "    \"\"\"\n",
    "    Fetch the webpage and extract the current month information from the h2 tag.\n",
    "    Expected h2 tag format:\n",
    "    <h2 id=\"december-2024-data-current-month\">December 2024 data (current month)</h2>\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(URL)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        h2_tag = soup.find(\"h2\", id=lambda x: x and \"data-current-month\" in x)\n",
    "        if h2_tag:\n",
    "            text = h2_tag.get_text(strip=True)\n",
    "            # Remove the \" (current month)\" part\n",
    "            current_month = text.split(\" (\")[0].strip()  # e.g. \"December 2024 data\"\n",
    "            return current_month, soup\n",
    "        else:\n",
    "            print(\"Could not find the current month information on the page.\")\n",
    "            return None, soup\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching the page: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def get_stored_update():\n",
    "    \"\"\"\n",
    "    Retrieve last_update.txt from the Kaggle dataset.\n",
    "    If it does not exist, create an empty one.\n",
    "    \"\"\"\n",
    "    kaggle_last_update_path = \"/kaggle/input/price-paid-data-202304/last_update.txt\"\n",
    "\n",
    "    if os.path.exists(kaggle_last_update_path):\n",
    "        print(\"Found last_update.txt in dataset. Loading...\")\n",
    "        os.system(f\"cp {kaggle_last_update_path} {LAST_UPDATE_FILE}\")  # Copy the file\n",
    "    else:\n",
    "        print(\"last_update.txt not found in dataset. Creating a new one.\")\n",
    "        with open(LAST_UPDATE_FILE, \"w\") as file:\n",
    "            file.write(\"\")  # Create an empty file\n",
    "\n",
    "    # Read and return the stored value\n",
    "    with open(LAST_UPDATE_FILE, \"r\") as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "def store_update(new_value):\n",
    "    \"\"\"Store the new update value in last_update.txt\"\"\"\n",
    "    with open(LAST_UPDATE_FILE, \"w\") as file:\n",
    "        file.write(new_value)\n",
    "\n",
    "    print(\"Updated last_update.txt with new value.\")\n",
    "\n",
    "\n",
    "def load_existing_monthly_files():\n",
    "    \"\"\"\n",
    "    Copy all CSV files from the Kaggle dataset folder in INPUT_DIR (except pp-complete.csv,\n",
    "    dataset-metadata.json, and last_update.txt) into the local DATA_DIR.\n",
    "    This will preserve previously accumulated monthly files.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(KAGGLE_INPUT_DIR):\n",
    "        print(f\"Kaggle input directory {KAGGLE_INPUT_DIR} not found!\")\n",
    "        return\n",
    "    for filename in os.listdir(KAGGLE_INPUT_DIR):\n",
    "        # Consider CSV files that are not pp-complete.csv, last_update.txt, or dataset-metadata.json\n",
    "        if filename.endswith('.csv') and filename not in [\"pp-complete.csv\", \"last_update.txt\", \"dataset-metadata.json\"]:\n",
    "            src = os.path.join(KAGGLE_INPUT_DIR, filename)\n",
    "            dest = os.path.join(DATA_DIR, filename)\n",
    "            if not os.path.exists(dest):\n",
    "                print(f\"Copying existing monthly file: {filename}\")\n",
    "                os.system(f\"cp {src} {dest}\")\n",
    "            else:\n",
    "                print(f\"Monthly file {filename} already exists locally; skipping copy.\")\n",
    "\n",
    "\n",
    "def find_monthly_csv_download_link(soup):\n",
    "    \"\"\"\n",
    "    Find the CSV download link for the monthly file by searching for \n",
    "    'pp-monthly-update-new-version.csv' in the href.\n",
    "    \"\"\"\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        if \"pp-monthly-update-new-version.csv\" in a[\"href\"]:\n",
    "            return a[\"href\"]\n",
    "    return None\n",
    "\n",
    "def find_csv_download_link(soup):\n",
    "    \"\"\"\n",
    "    Find the CSV download link for the complete dataset by searching for \n",
    "    'pp-complete.csv' in the href.\n",
    "    \"\"\"\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        if \"pp-complete.csv\" in a[\"href\"]:\n",
    "            return a[\"href\"]\n",
    "    return None\n",
    "\n",
    "def get_monthly_file_name(soup):\n",
    "    \"\"\"\n",
    "    Extract the monthly file name from the h2 tag.\n",
    "    For example, if the h2 text is 'December 2024 data (current month)',\n",
    "    return 'December 2024 data.csv'.\n",
    "    \"\"\"\n",
    "    h2_tag = soup.find(\"h2\", id=lambda x: x and \"data-current-month\" in x)\n",
    "    if h2_tag:\n",
    "        text = h2_tag.get_text(strip=True)\n",
    "        name = text.split(\" (\")[0]  # e.g. \"December 2024 data\"\n",
    "        return f\"{name}.csv\"\n",
    "    return None\n",
    "\n",
    "def download_file(url, output_filename):\n",
    "    \"\"\"\n",
    "    Download the file from the given URL to DATA_DIR using the specified output filename.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(DATA_DIR, output_filename)\n",
    "    \n",
    "    print(f\"Downloading to {file_path}...\")\n",
    "    \n",
    "    try:\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            total_size = int(r.headers.get('content-length', 0))\n",
    "            downloaded = 0\n",
    "            chunk_size = 8192  # 8KB chunks\n",
    "            \n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        downloaded += len(chunk)\n",
    "                        print(f\"\\rDownloaded {downloaded / 1e6:.2f} MB\", end='')\n",
    "        print(\"\\nDownload complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to check for an update based on the current month.\n",
    "    If the current month (extracted from the h2 tag) has changed since the last run,\n",
    "    download the monthly file (if not already downloaded) first, then the complete file.\n",
    "    \"\"\"\n",
    "\n",
    "    load_existing_monthly_files()\n",
    "\n",
    "    \n",
    "    current_month, soup = get_current_month()\n",
    "    if not current_month:\n",
    "        print(\"No current month information found. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    stored_month = get_stored_update()\n",
    "    \n",
    "    if stored_month == current_month:\n",
    "        print(\"No update detected for the current month. Skipping download.\")\n",
    "    else:\n",
    "        print(f\"New update detected: {current_month} (Previous: {stored_month})\")\n",
    "        \n",
    "        # --- Download the monthly file if not already present ---\n",
    "        monthly_link = find_monthly_csv_download_link(soup)\n",
    "        monthly_filename = get_monthly_file_name(soup)\n",
    "        if monthly_link and monthly_filename:\n",
    "            monthly_file_path = os.path.join(DATA_DIR, monthly_filename)\n",
    "            if os.path.exists(monthly_file_path):\n",
    "                print(f\"Monthly file {monthly_filename} already exists. Skipping download for monthly file.\")\n",
    "            else:\n",
    "                if monthly_link.startswith(\"/\"):\n",
    "                    monthly_link = \"https://www.gov.uk\" + monthly_link\n",
    "                print(f\"Monthly file link found: {monthly_link}\")\n",
    "                print(f\"Downloading monthly file as: {monthly_filename}\")\n",
    "                download_file(monthly_link, monthly_filename)\n",
    "        else:\n",
    "            print(\"Could not find the monthly file download link or file name.\")\n",
    "        \n",
    "        # --- Download the complete (huge) file (always replace) ---\n",
    "        complete_link = find_csv_download_link(soup)\n",
    "        if complete_link:\n",
    "            if complete_link.startswith(\"/\"):\n",
    "                complete_link = \"https://www.gov.uk\" + complete_link\n",
    "            # Use a constant filename for the complete file\n",
    "            complete_filename = \"pp-complete.csv\"\n",
    "            print(f\"Complete file link found: {complete_link}\")\n",
    "            print(f\"Downloading complete file as: {complete_filename}\")\n",
    "            download_file(complete_link, complete_filename)\n",
    "        else:\n",
    "            print(\"Could not find the complete file download link.\")\n",
    "        \n",
    "        # Update the stored update key with the current month\n",
    "        store_update(current_month)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e786c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T20:37:45.227397Z",
     "iopub.status.busy": "2025-02-18T20:37:45.226350Z",
     "iopub.status.idle": "2025-02-18T20:37:45.412772Z",
     "shell.execute_reply": "2025-02-18T20:37:45.411945Z"
    },
    "papermill": {
     "duration": 0.896498,
     "end_time": "2025-02-18T20:37:45.414666",
     "exception": false,
     "start_time": "2025-02-18T20:37:44.518168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "kaggle_api_key =  user_secrets.get_secret(\"kaggle-api\")\n",
    "\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"lorentzyeung\"\n",
    "os.environ[\"KAGGLE_KEY\"] = kaggle_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1117478b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T20:37:46.791783Z",
     "iopub.status.busy": "2025-02-18T20:37:46.791424Z",
     "iopub.status.idle": "2025-02-18T20:37:46.797968Z",
     "shell.execute_reply": "2025-02-18T20:37:46.796997Z"
    },
    "papermill": {
     "duration": 0.675018,
     "end_time": "2025-02-18T20:37:46.799507",
     "exception": false,
     "start_time": "2025-02-18T20:37:46.124489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset-metadata.json created at ./data/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define metadata\n",
    "metadata = {\n",
    "    \"title\": \"UK Property Price official data (Monthly Update)\", \n",
    "    \"id\": \"lorentzyeung/price-paid-data-202304\",  # (URL slug)\n",
    "    \"licenses\": [{\"name\": \"CC0-1.0\"}]  # License (default is CC0-1.0 for public datasets)\n",
    "}\n",
    "\n",
    "# Save metadata to the ./data/ folder\n",
    "metadata_path = \"./data/dataset-metadata.json\"\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(f\"dataset-metadata.json created at {metadata_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68837495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T20:37:48.239979Z",
     "iopub.status.busy": "2025-02-18T20:37:48.239583Z",
     "iopub.status.idle": "2025-02-18T20:39:07.095567Z",
     "shell.execute_reply": "2025-02-18T20:39:07.094222Z"
    },
    "papermill": {
     "duration": 79.59498,
     "end_time": "2025-02-18T20:39:07.097808",
     "exception": false,
     "start_time": "2025-02-18T20:37:47.502828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found in ./data/. Proceeding with dataset update...\n",
      "Starting upload for file last_update.txt\r\n",
      "100%|█████████████████████████████████████████| 18.0/18.0 [00:00<00:00, 28.1B/s]\r\n",
      "Upload successful: last_update.txt (18B)\r\n",
      "Starting upload for file December 2024 data.csv\r\n",
      "100%|██████████████████████████████████████| 13.0M/13.0M [00:00<00:00, 17.7MB/s]\r\n",
      "Upload successful: December 2024 data.csv (13MB)\r\n",
      "Starting upload for file pp-complete.csv\r\n",
      "100%|██████████████████████████████████████| 4.86G/4.86G [01:14<00:00, 70.0MB/s]\r\n",
      "Upload successful: pp-complete.csv (5GB)\r\n",
      "Dataset version is being created. Please check progress at https://www.kaggle.com/lorentzyeung/price-paid-data-202304\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if at least one file exists in ./data/\n",
    "if len(os.listdir(DATA_DIR)) > 0:\n",
    "    print(\"Files found in ./data/. Proceeding with dataset update...\")\n",
    "    \n",
    "    # Update dataset\n",
    "    !kaggle datasets version -p ./data -m \"Automatic update: last_update.txt retrieved and updated, new monthly file added, pp-complete.csv replaced\" --dir-mode=tar\n",
    "else:\n",
    "    print(\"No files in ./data/. Skipping dataset update.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc61936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T20:39:08.591464Z",
     "iopub.status.busy": "2025-02-18T20:39:08.591063Z",
     "iopub.status.idle": "2025-02-18T20:39:08.722759Z",
     "shell.execute_reply": "2025-02-18T20:39:08.721305Z"
    },
    "papermill": {
     "duration": 0.869384,
     "end_time": "2025-02-18T20:39:08.725026",
     "exception": false,
     "start_time": "2025-02-18T20:39:07.855642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.9G\r\n",
      "-rw-r--r-- 1 nobody nogroup  13M Feb 18 20:30 'December 2023 data.csv'\r\n",
      "-rw-r--r-- 1 nobody nogroup  13M Feb 18 20:30 'December 2024 data.csv'\r\n",
      "-rw-r--r-- 1 nobody nogroup   37 Feb 18 20:30  last_update.txt\r\n",
      "-rw-r--r-- 1 nobody nogroup 4.9G Feb 18 20:32  pp-complete.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /kaggle/input/price-paid-data-202304\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c95f97",
   "metadata": {
    "papermill": {
     "duration": 0.725723,
     "end_time": "2025-02-18T20:39:10.167246",
     "exception": false,
     "start_time": "2025-02-18T20:39:09.441523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3754341,
     "sourceId": 10787242,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 331.308716,
   "end_time": "2025-02-18T20:39:11.514486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-18T20:33:40.205770",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
